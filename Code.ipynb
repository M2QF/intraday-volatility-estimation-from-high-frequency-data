{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import async_lru\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@async_lru.alru_cache(maxsize=128)\n",
    "async def get_data(url: str) -> bytes:\n",
    "    \"\"\"Gets data from URL\n",
    "\n",
    "    Args:\n",
    "        url (str): URL to query\n",
    "\n",
    "    Returns:\n",
    "        bytes: pickled data\n",
    "    \"\"\"\n",
    "    print(f\"Getting data from {url}\")\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url, headers={\"Accept\": \"python/pickle\"}) as response:\n",
    "            return await response.read()\n",
    "\n",
    "\n",
    "@async_lru.alru_cache(maxsize=128)\n",
    "async def head_data(url: str) -> dict:\n",
    "    \"\"\"Gets data from URL\n",
    "\n",
    "    Args:\n",
    "        url (str): URL to query\n",
    "\n",
    "    Returns:\n",
    "        dict: headers of the response\n",
    "    \"\"\"\n",
    "    print(f\"Heading data from {url}\")\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.head(url, headers={\"Accept\": \"python/pickle\"}) as response:\n",
    "            return dict(response.headers.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_begin = 2009\n",
    "\n",
    "\n",
    "async def get_prices() -> pd.DataFrame:\n",
    "    \"\"\"Get all prices\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe of prices\n",
    "    \"\"\"\n",
    "    base_url = \"https://high-frequency-data.shriimpe.fr/api/data/price?start_date={}-01-01&end_date={}-12-31\"\n",
    "\n",
    "    requests = [\n",
    "        get_data(base_url.format(year, year))\n",
    "        for year in range(time_begin, datetime.now().year + 1)\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for request in asyncio.as_completed(requests, timeout=600):\n",
    "        buf = io.BytesIO(await request)\n",
    "        results.append(pd.read_pickle(buf))\n",
    "\n",
    "    return pd.concat(results)\n",
    "\n",
    "\n",
    "async def head_prices() -> dict:\n",
    "    \"\"\"Process HEAD request for prices\n",
    "\n",
    "    Yields:\n",
    "        Iterator[dict]: headers of requests\n",
    "    \"\"\"\n",
    "    base_url = \"https://high-frequency-data.shriimpe.fr/api/data/price?start_date={}-01-01&end_date={}-12-31\"\n",
    "\n",
    "    requests = [\n",
    "        head_data(base_url.format(year, year))\n",
    "        for year in range(time_begin, datetime.now().year + 1)\n",
    "    ]\n",
    "\n",
    "    for request in asyncio.as_completed(requests, timeout=600):\n",
    "        yield await request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"data/prices_{datetime.today().strftime(\"%Y-%m-%d\")}.pkl\"):\n",
    "    async for headers in head_prices():\n",
    "        display(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f\"data/prices_{datetime.today().strftime(\"%Y-%m-%d\")}.pkl\"):\n",
    "    print(\"Reading prices from Pickle file\")\n",
    "    print(\"File size:\", os.path.getsize(f\"data/prices_{datetime.today().strftime(\"%Y-%m-%d\")}.pkl\") / 1e6, \"MB\")\n",
    "    prices = pd.read_pickle(f\"data/prices_{datetime.today().strftime(\"%Y-%m-%d\")}.pkl\")\n",
    "else:\n",
    "    print(\"Removing previous files...\")\n",
    "    files = os.listdir(\"data/\")\n",
    "    for file in files:\n",
    "        if file.startswith(\"prices_\") and file.endswith(\".pkl\"):\n",
    "            print(f\"Removing {file}\")\n",
    "            os.remove(file)\n",
    "    \n",
    "    print(\"Gathering data from API...\")\n",
    "    prices = await get_prices()\n",
    "\n",
    "    prices.drop(columns=[\"volume\"], inplace=True)\n",
    "\n",
    "    prices[\"date_time\"] = pd.to_datetime(prices[\"date_time\"])\n",
    "\n",
    "    prices.sort_values(by=\"date_time\", inplace=True)\n",
    "\n",
    "    prices.reset_index(drop=True, inplace=True)\n",
    "    prices.to_pickle(f\"data/prices_{datetime.today().strftime(\"%Y-%m-%d\")}.pkl\")\n",
    "\n",
    "\n",
    "print(f\"{prices.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(prices.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(prices.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = prices[\"price\"].diff()\n",
    "display(diff.loc[diff > 10].index)\n",
    "prices.drop(diff.loc[diff > 10].index, inplace=True)\n",
    "prices.drop(prices[prices[\"price\"] < 45].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = prices[\n",
    "    prices[\"date_time\"].apply(\n",
    "        lambda x: x.hour == 9 and x.minute == 30 and x.second == 0\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.plot(prices[\"date_time\"], prices[\"price\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Prices from high frequency data\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.plot(prices[\"date_time\"], prices[\"price\"], label=\"High frequency prices\")\n",
    "plt.plot(\n",
    "    daily[\"date_time\"],\n",
    "    daily[\"price\"],\n",
    "    label=\"Daily opening prices\",\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = prices[\n",
    "    (prices[\"date_time\"] >= datetime(2022, 1, 4))\n",
    "    & (prices[\"date_time\"] <= datetime(2022, 1, 4, 16))\n",
    "].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Prices from high frequency data over one day\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.plot(day[\"date_time\"], day[\"price\"], label=\"High frequency prices\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[\"log_prices\"] = np.log(prices[\"price\"])\n",
    "day[\"log_prices\"] = np.log(day[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Log prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Log price\")\n",
    "plt.plot(prices[\"date_time\"], prices[\"log_prices\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_variable_freq: dict[str, pd.DataFrame] = {}\n",
    "for interval in (\n",
    "    \"10 seconds\",\n",
    "    \"20 seconds\",\n",
    "    \"30 seconds\",\n",
    "    \"35 seconds\",\n",
    "    \"40 seconds\",\n",
    "    \"45 seconds\",\n",
    "    \"50 seconds\",\n",
    "    \"55 seconds\",\n",
    "    \"1 minutes\",\n",
    "    \"90 seconds\",\n",
    "    \"2 minutes\",\n",
    "    \"150 seconds\",\n",
    "    \"3 minutes\",\n",
    "    \"4 minutes\",\n",
    "    \"5 minutes\",\n",
    "    \"6 minutes\",\n",
    "    \"7 minutes\",\n",
    "    \"8 minutes\",\n",
    "    \"10 minutes\",\n",
    "    \"11 minutes\",\n",
    "    \"12 minutes\",\n",
    "    \"13 minutes\",\n",
    "    \"14 minutes\",\n",
    "    \"15 minutes\",\n",
    "):\n",
    "    dates = [day.iloc[0, 0]]\n",
    "\n",
    "    for date in day[\"date_time\"]:\n",
    "        if date - dates[-1] >= pd.Timedelta(interval):\n",
    "            dates.append(date)\n",
    "\n",
    "    prices_variable_freq[interval] = day[day[\"date_time\"].isin(dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatilities = {}\n",
    "for interval in prices_variable_freq:\n",
    "    volatilities[interval] = np.sum(\n",
    "        ((prices_variable_freq[interval][\"log_prices\"].diff().dropna())) ** 2\n",
    "    )\n",
    "\n",
    "display(volatilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Realized volatility dynamics\")\n",
    "plt.plot(list(volatilities.keys()), list(volatilities.values()), \"g+-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = {}\n",
    "for interval in prices_variable_freq:\n",
    "    diffs[interval] = prices_variable_freq[interval][\"log_prices\"].diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariances = {}\n",
    "for interval in diffs:\n",
    "    covariances[interval] = np.cov(diffs[interval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Covariance dynamics\")\n",
    "plt.plot(list(covariances.keys()), list(covariances.values()), \"r+-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microstructure noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[\"log_returns\"] = np.log(10 + prices[\"price\"].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Log returns\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Log returns\")\n",
    "plt.plot(prices[\"date_time\"], prices[\"log_returns\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf = sm.tsa.acf(prices[\"log_returns\"], missing=\"conservative\", nlags=100)\n",
    "acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.stem(range(2, len(acf)), acf[2:])\n",
    "plt.title(\"Autocorrelation Function (ACF): {} values\".format(len(acf)))\n",
    "plt.xlabel(\"Lag\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microstructure noise size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_year = prices[prices[\"date_time\"] >= datetime(datetime.today().year - 1, 1, 1)]\n",
    "last_year.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_per_day = {}\n",
    "\n",
    "for day in last_year[\"date_time\"].dt.date.unique():\n",
    "    data: pd.DataFrame = last_year[last_year[\"date_time\"].dt.date == day][\"log_returns\"]\n",
    "    volatility_per_day[day] = (np.sum((data.diff().dropna()) ** 2), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microsturcture_noise_size = {}\n",
    "for vol in volatility_per_day:\n",
    "    microsturcture_noise_size[vol] = np.sqrt(\n",
    "        1 / (2 * volatility_per_day[vol][1]) * volatility_per_day[vol][0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Microstructure noise size per day\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Microstructure noise size\")\n",
    "plt.plot(\n",
    "    list(microsturcture_noise_size.keys()),\n",
    "    list(microsturcture_noise_size.values()),\n",
    "    \"r+-\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Histogram of microstructure noise size\")\n",
    "plt.xlabel(\"Microstructure noise size\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axis(xmin=0, xmax=max(microsturcture_noise_size.values()))\n",
    "plt.hist(microsturcture_noise_size.values(), bins=100, density=True, label=\"Data\")\n",
    "plt.plot(\n",
    "    np.linspace(0, max(microsturcture_noise_size.values()), 1000),\n",
    "    norm.pdf(\n",
    "        np.linspace(0, max(microsturcture_noise_size.values()), 1000),\n",
    "        loc=np.mean(list(microsturcture_noise_size.values())),\n",
    "        scale=np.std(list(microsturcture_noise_size.values())),\n",
    "    ),\n",
    "    label=\"Fitted curve\",\n",
    ")\n",
    "print(\n",
    "    \"Mean:\",\n",
    "    np.mean(list(microsturcture_noise_size.values())),\n",
    "    \"\\nStandard deviation:\",\n",
    "    np.std(list(microsturcture_noise_size.values())),\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimated daily volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Volatility per day\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.plot(\n",
    "    list(volatility_per_day.keys()), [x[0] for x in volatility_per_day.values()], \"g+-\"\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
